{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a427e4-8a8f-4743-9929-b952dcef2c96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.5 MB 1.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/11.5 MB 987.4 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.5 MB 987.4 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.5 MB 987.4 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.5 MB 774.0 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/11.5 MB 774.0 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/11.5 MB 774.0 kB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 593.8 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 593.8 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 593.8 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 593.8 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 511.4 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 511.4 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 511.4 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 1.8/11.5 MB 513.5 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 2.1/11.5 MB 548.7 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.4/11.5 MB 588.6 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.6/11.5 MB 631.7 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 663.2 kB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 693.8 kB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 719.0 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 719.0 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 719.0 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 3.7/11.5 MB 696.8 kB/s eta 0:00:12\n",
      "   ------------- -------------------------- 3.9/11.5 MB 542.4 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 3.9/11.5 MB 542.4 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 3.9/11.5 MB 542.4 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 3.9/11.5 MB 542.4 kB/s eta 0:00:14\n",
      "   ------------- -------------------------- 3.9/11.5 MB 542.4 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.2/11.5 MB 503.3 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 4.2/11.5 MB 503.3 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 4.2/11.5 MB 503.3 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 4.5/11.5 MB 509.3 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 4.5/11.5 MB 509.3 kB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 513.9 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 521.6 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 521.6 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 5.2/11.5 MB 534.0 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 5.2/11.5 MB 534.0 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 5.5/11.5 MB 536.0 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 5.5/11.5 MB 536.0 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 5.8/11.5 MB 536.2 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 5.8/11.5 MB 536.2 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 5.8/11.5 MB 536.2 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 5.8/11.5 MB 536.2 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 6.0/11.5 MB 517.0 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 6.0/11.5 MB 517.0 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 6.3/11.5 MB 525.0 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.3/11.5 MB 525.0 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 529.1 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 529.1 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 529.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 519.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 519.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 519.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 519.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 519.1 kB/s eta 0:00:10\n",
      "   ------------------------ --------------- 7.1/11.5 MB 499.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.1/11.5 MB 499.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.1/11.5 MB 499.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.1/11.5 MB 499.7 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 7.3/11.5 MB 486.6 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 7.3/11.5 MB 486.6 kB/s eta 0:00:09\n",
      "   -------------------------- ------------- 7.6/11.5 MB 490.9 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 7.6/11.5 MB 490.9 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 7.9/11.5 MB 495.4 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 7.9/11.5 MB 495.4 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 501.3 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 509.4 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 8.7/11.5 MB 517.7 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 8.7/11.5 MB 517.7 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 8.9/11.5 MB 521.3 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.9/11.5 MB 521.3 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.9/11.5 MB 521.3 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 9.2/11.5 MB 514.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 9.2/11.5 MB 514.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 9.2/11.5 MB 514.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 9.2/11.5 MB 514.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 9.2/11.5 MB 514.8 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 9.4/11.5 MB 499.3 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.7/11.5 MB 475.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 461.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 444.9 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 444.9 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 444.9 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 444.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.5/11.5 MB 436.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.5/11.5 MB 436.8 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.7/11.5 MB 441.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.0/11.5 MB 448.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  11.3/11.5 MB 455.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 461.5 kB/s eta 0:00:00\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/12.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 1.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 1.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/12.6 MB 1.8 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.6/12.6 MB 1.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.9/12.6 MB 1.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.9/12.6 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 1.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.9/12.6 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 4.2/12.6 MB 1.4 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.7/12.6 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 5.0/12.6 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 1.4 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.8/12.6 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.8/12.6 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.6 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.6 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.6 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.6/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.6/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.8/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.8/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.6/12.6 MB 993.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.6/12.6 MB 993.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.6/12.6 MB 993.1 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.9/12.6 MB 950.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.9/12.6 MB 950.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 8.1/12.6 MB 944.3 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.4/12.6 MB 949.0 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 8.7/12.6 MB 953.6 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 8.7/12.6 MB 953.6 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 943.2 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 943.2 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 943.2 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 943.2 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 899.7 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 899.7 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 899.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.4/12.6 MB 861.0 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.4/12.6 MB 861.0 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.4/12.6 MB 861.0 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.7/12.6 MB 842.4 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 10.0/12.6 MB 841.2 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 10.2/12.6 MB 846.6 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.5/12.6 MB 854.2 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 863.7 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 874.0 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 881.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.6 MB 888.4 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 11.8/12.6 MB 887.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 887.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 884.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 884.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 873.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 873.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 873.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 861.6 kB/s eta 0:00:00\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "Successfully installed numpy-2.1.3 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2024.2 six-1.16.0 tzdata-2024.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\srinivasu\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e15e80-a8ec-4386-9646-4dca5b804483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "df1 = pd.read_csv('level1TestCases - level1.csv')\n",
    "df2 = pd.read_csv('level2TestCases - level2.csv')\n",
    "df3 = pd.read_csv('level3TestCases - level3.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79f47ed-d606-4f36-aa51-9a9a981fbbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>inappropriate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a freaking jerk.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim is an ashsole</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not even able to clean shit off the freaking f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is also able to sell any crap we have in ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All cleaners are dumb, but this one is just a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  difficulty_level  \\\n",
       "0                              What a freaking jerk.                 1   \n",
       "1                                  Jim is an ashsole                 1   \n",
       "2  Not even able to clean shit off the freaking f...                 1   \n",
       "3  He is also able to sell any crap we have in ou...                 1   \n",
       "4  All cleaners are dumb, but this one is just a ...                 1   \n",
       "\n",
       "   inappropriate  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a89398-0aa6-4d56-9127-fd0ad0db9ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>inappropriate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim is gay!</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim is acting so gay.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jim is gay</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim is such a queer.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jim is gey</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  difficulty_level  inappropriate\n",
       "0            Jim is gay!                 2              1\n",
       "1  Jim is acting so gay.                 2              1\n",
       "2             Jim is gay                 2              0\n",
       "3   Jim is such a queer.                 2              1\n",
       "4             Jim is gey                 2              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f320ba3b-9ad6-4e61-b0d1-44bc197b6844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>inappropriate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Back in colonial times he would have been beat...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This guy is just dragging his feet around.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jim is really a woman</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cannot say Jenny is the best, but she is tryin...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ken definitely likes men.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  difficulty_level  \\\n",
       "0  Back in colonial times he would have been beat...                 3   \n",
       "1         This guy is just dragging his feet around.                 3   \n",
       "2                              Jim is really a woman                 3   \n",
       "3  Cannot say Jenny is the best, but she is tryin...                 3   \n",
       "4                          Ken definitely likes men.                 3   \n",
       "\n",
       "   inappropriate  \n",
       "0              1  \n",
       "1              0  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77010233-18db-4db8-a3ee-292842fbf908",
   "metadata": {},
   "source": [
    "# Explanation of Metrics:\n",
    "- Accuracy: Measures overall correctness.\n",
    "- Precision: Measures the percentage of correctly predicted positive cases.\n",
    "- Recall: Measures the percentage of actual positive cases correctly predicted.\n",
    "- True Positives (TP): Correctly predicted inappropriate comments.\n",
    "- True Negatives (TN): Correctly predicted appropriate comments.\n",
    "- False Positives (FP): Incorrectly predicted inappropriate comments.\n",
    "- False Negatives (FN): Missed inappropriate comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcfe63-204d-465d-abd6-76df79ec824b",
   "metadata": {},
   "source": [
    "# Baseline for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d7e0a6-8149-42b6-8b42-e66e6e26a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Define a list of inappropriate words (example words)\n",
    "inappropriate_words = ['anus', 'arse', 'arsehole', 'ass', 'ass-hat', 'ass-jabber', 'ass-pirate', 'assbag', 'assbandit', 'assbanger', 'assbite', 'assclown', 'asscock', 'asscracker', 'asses', 'assface', 'assfuck', 'assfucker', 'assgoblin', 'asshat', 'asshead', 'asshole', 'asshopper', 'assjacker', 'asslick', 'asslicker', 'assmonkey', 'assmunch', 'assmuncher', 'assnigger', 'asspirate', 'assshit', 'assshole', 'asssucker', 'asswad', 'asswipe', 'balls', 'bampot', 'bastard', 'beaner', 'bint', 'bitch', 'bitchass', 'bitches', 'bitchtits', 'bitchy', 'bloody', 'blowjob', 'blowjob', 'bollocks', 'bollox', 'boner', 'brotherfucker', 'bugger', 'bullshit', 'bumblefuck', 'butt plug', 'butt-pirate', 'buttfucka', 'buttfucker', 'camel toe', 'carpetmuncher', 'chinc', 'chink', 'choad', 'chode', 'clit', 'clitface', 'clitfuck', 'clusterfuck', 'cock', 'cockass', 'cockbite', 'cockburger', 'cockface', 'cockfucker', 'cockhead', 'cockjockey', 'cockknoker', 'cockmaster', 'cockmongler', 'cockmongruel', 'cockmonkey', 'cockmuncher', 'cocknose', 'cocknugget', 'cockshit', 'cocksmith', 'cocksmoke', 'cocksmoker', 'cocksniffer', 'cocksucker', 'cockwaffle', 'coochie', 'coochy', 'coon', 'cooter', 'cracker', 'cum', 'cumbubble', 'cumdumpster', 'cumguzzler', 'cumjockey', 'cumslut', 'cumtart', 'cunnie', 'cunnilingus', 'cunt', 'cuntass', 'cuntface', 'cunthole', 'cuntlicker', 'cuntrag', 'cuntslut', 'dago', 'dammit', 'damn', 'dang', 'deggo', 'dick', 'dickbag', 'dickbeaters', 'dickface', 'dickfuck', 'dickfucker', 'dickhead', 'dickhole', 'dickjuice', 'dickmilk', 'dickmonger', 'dicks', 'dickslap', 'dicksucker', 'dicksucking', 'dickwad', 'dickweasel', 'dickweed', 'dickwod', 'dike', 'dildo', 'dipshit', 'doochbag', 'dookie', 'douche', 'douche-fag', 'douchebag', 'douchewaffle', 'dumass', 'dumb ass', 'dumbass', 'dumbfuck', 'dumbshit', 'dumshit', 'dyke', 'fag', 'fagbag', 'fagfucker', 'faggit', 'faggot', 'faggotcock', 'fagtard', 'fatass', 'fellatio', 'feltch', 'flamer', 'fool', 'frickin', 'friggin', 'f*ck', 'fuck', 'fuckass', 'fuckbag', 'fuckboy', 'fuckbrain', 'fuckbutt', 'fucked', 'fucker', 'fuckersucker', 'fuckface', 'fuckhead', 'fuckhole', 'fuckin', 'fucking', 'fucknut', 'fucknutt', 'fuckoff', 'fucks', 'fuckstick', 'fucktard', 'fucktart', 'fuckup', 'fuckwad', 'fuckwit', 'fuckwitt', 'fudgepacker', 'gay', 'gayass', 'gaybob', 'gaydo', 'gayfuck', 'gayfuckist', 'gaylord', 'gaytard', 'gaywad', 'goddamn', 'goddamnit', 'gooch', 'gook', 'gringo', 'guido', 'handjob', 'hard on', 'heeb', 'helminth', 'hell', 'ho', 'hoe', 'hoebag', 'homo', 'homodumbshit', 'honkey', 'humping', 'idiot', 'imbecile', 'jackass', 'jap', 'jerk off', 'jerk wad', 'jigaboo', 'jizz', 'jungle bunny', 'junglebunny', 'kike', 'kooch', 'kootch', 'kraut', 'kunt', 'kyke', 'lameass', 'lesbian', 'lesbo', 'lezzie', 'mcfagget', 'mick', 'midget', 'minge', 'moron', 'mothafucka', 'mothafuckin', 'motherfuck', 'motherfucker', 'motherfucking', 'muff', 'muffdiver', 'munging', 'negro', 'nigaboo', 'nigga', 'nigger', 'niggers', 'niglet', 'nutter', 'nut sack', 'nutsack', 'paki', 'panooch', 'pecker', 'peckerhead', 'penis', 'penisbanger', 'penisfucker', 'penispuffer', 'piss', 'pissed', 'pissed off', 'pissflaps', 'polesmoker', 'pollock', 'poon', 'poonani', 'poonany', 'poontang', 'porch monkey', 'porchmonkey', 'prick', 'punanny', 'punta', 'pussies', 'pussy', 'pussylicking', 'puto', 'queef', 'queer', 'queerbait', 'queerhole', 'renob', 'retard', 'rimjob', 'ruski', 'sand nigger', 'sandnigger', 'schlong', 'schmuck', 'scrote', 'scullion', 'shag', 'shit', 'shitass', 'shitbag', 'shitbagger', 'shitbrains', 'shitbreath', 'shitcanned', 'shitcunt', 'shitdick', 'shitface', 'shitfaced', 'shithead', 'shithole', 'shithouse', 'shitspitter', 'shitstain', 'shitter', 'shittiest', 'shitting', 'shitty', 'shiz', 'shiznit', 'skank', 'skeet', 'skullfuck', 'slag', 'slapper', 'slut', 'slutbag', 'slubberdegullion', 'smeg', 'snatch', 'sodding', 'sonofabitch', 'spastic', 'spic', 'spick', 'splooge', 'spook', 'sucka', 'suckass', 'sucker', 'suckers', 'tard', 'testicle', 'thundercunt', 'tit', 'titfuck', 'tits', 'tittyfuck', 'trollop', 'twat', 'twatlips', 'twats', 'twatwaffle', 'unclefucker', 'va-j-j', 'vag', 'vagina', 'vajayjay', 'vjayjay', 'wank', 'wanker', 'wankjob', 'wetback', 'whore', 'whorebag', 'whoreface', 'wop', 'wtf','ass', 'asses', 'asshole', 'assholes', 'buttfuck', 'cocksucker', 'cocksucking', 'cunt', 'cuntlicker', 'cunts', 'cyberfuc', 'cyberfuck', 'cyberfucked', 'cyberfucker', 'cyberfuckers', 'cyberfucking', 'dick', 'fag', 'fagging', 'faggot', 'faggs', 'fagot', 'fagots', 'fags', 'fingerfuck', 'fingerfucked', 'fingerfucker', 'fingerfuckers', 'fingerfucking', 'fingerfucks', 'fisting', 'fistfuck', 'fistfucked', 'fistfucker', 'fistfuckers', 'fistfucking', 'fistfuckings', 'fistfucks', 'footfuck', 'fuck', 'fucked', 'fucker', 'fuckers', 'fuckfest', 'fuckin', 'fucking', 'fuckings', 'fuckme', 'f u c k', 'fu ck', 'fuc k', 'f uck', 'fucks', 'fucktard', 'fucktards', 'f\\\\*uck', 'fu\\\\*ck', 'fuc\\\\*k', 'fuk', 'fuks', 'gangbang', 'gangbanged', 'gangbangs', 'gaysex', 'gay sex', 'hores', 'incest', 'jackoff', 'jack-off', 'jerk-off', 'kunt', 'mothafuck', 'mothafucka', 'mothafuckas', 'mothafuckaz', 'mothafucked', 'mothafucker', 'mothafuckers', 'mothafuckin', 'mothafucking', 'mothafuckings', 'mothafucks', 'motherfuck', 'motherfucked', 'motherfucker', 'motherfuckers', 'motherfuckin', 'motherfucking', 'motherfuckings', 'motherfucks', 'nigger', 'niggers', 'pecker', 'pedofile', 'pedofilia', 'pedophile', 'pedophilia', 'p e n i s', 'phuk', 'phuked', 'phuking', 'phukked', 'phukking', 'phuks', 'phuq', 'rimjob', 'rimming', 'semen', 'shagged', 'shit', 'shited', 'shitfull', 'shiting', 'shitings', 'shits', 'shitted', 'shitter', 'shitters', 'shitting', 'shittings', 'shitty', 'skank', 'skanks', 'slut', 'sluts', 'spermed', 'sperming', 'titfuck', 'titfucker', 'titjob', 'titties', 'titty', 'twat', 'wank', 'wanker', 'whore', 'whores','crap', 'minging','fool', 'idiot', 'moron', 'imbecile', 'gay', 'lesbian', 'queer', 'munging']\n",
    "\n",
    "# Function to check if any inappropriate word is in the sentence\n",
    "def check_words_in_sentence(sentence, word_list):\n",
    "    for word in word_list:\n",
    "        if word in sentence.split():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a424f4aa-bcee-476e-92c1-fb258e40a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444444444444444\n",
      "Precision: 1.0\n",
      "Recall: 0.4444444444444444\n",
      "True Positives: 8\n",
      "True Negatives: 0\n",
      "False Positives: 0\n",
      "False Negatives: 10\n"
     ]
    }
   ],
   "source": [
    "# Apply the function and get predictions (1 for inappropriate, 0 for appropriate)\n",
    "df1['predicted_inappropriate'] = df1['text'].apply(lambda x: int(check_words_in_sentence(x, inappropriate_words)))\n",
    "\n",
    "# Calculate true labels and predicted labels\n",
    "y_true = df1['inappropriate']\n",
    "y_pred = df1['predicted_inappropriate']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6155e40-c21e-461c-9801-e65ab16203c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35294117647058826\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "True Positives: 0\n",
      "True Negatives: 6\n",
      "False Positives: 2\n",
      "False Negatives: 9\n"
     ]
    }
   ],
   "source": [
    "# Apply the function and get predictions (1 for inappropriate, 0 for appropriate)\n",
    "df2['predicted_inappropriate'] = df2['text'].apply(lambda x: int(check_words_in_sentence(x, inappropriate_words)))\n",
    "\n",
    "# Calculate true labels and predicted labels\n",
    "y_true = df2['inappropriate']\n",
    "y_pred = df2['predicted_inappropriate']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce94125-381b-4f54-aa06-5de6d9c100a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23529411764705882\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "True Positives: 0\n",
      "True Negatives: 4\n",
      "False Positives: 0\n",
      "False Negatives: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivasu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Apply the function and get predictions (1 for inappropriate, 0 for appropriate)\n",
    "df3['predicted_inappropriate'] = df3['text'].apply(lambda x: int(check_words_in_sentence(x, inappropriate_words)))\n",
    "\n",
    "# Calculate true labels and predicted labels\n",
    "y_true3 = df3['inappropriate']\n",
    "y_pred3 = df3['predicted_inappropriate']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true3, y_pred3)\n",
    "precision = precision_score(y_true3, y_pred3)\n",
    "recall = recall_score(y_true3, y_pred3)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true3, y_pred3).ravel()\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2accbe41-0cad-4809-b1d8-283365b87f4c",
   "metadata": {},
   "source": [
    "# Grid Search BEST Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e002aad6-bcdf-4e5f-be4a-4a2135805167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivasu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.5.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\srinivasu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.5.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\srinivasu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.5.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\srinivasu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_pipeline = joblib.load(\"best_model_grid_search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b97cc23-2783-42c0-9b50-80ac77ad6cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 1.0\n",
      "True Positives (TP): 14\n",
      "False Positives (FP): 0\n",
      "True Negatives (TN): 0\n",
      "False Negatives (FN): 4\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_test = df1['text']\n",
    "y_test = df1['inappropriate']\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and precision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix elements\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {recall}\")\n",
    "print(f\"Recall: {precision}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0899bdb-0b13-4b7c-9940-55262d97ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5294117647058824\n",
      "Precision: 0.5555555555555556\n",
      "Recall: 0.5555555555555556\n",
      "True Positives (TP): 5\n",
      "False Positives (FP): 4\n",
      "True Negatives (TN): 4\n",
      "False Negatives (FN): 4\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_test = df2['text']\n",
    "y_test = df2['inappropriate']\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and precision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix elements\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {precision}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f6d0d6c-137a-426d-899e-74d689c78f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35294117647058826\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "True Positives (TP): 3\n",
      "False Positives (FP): 1\n",
      "True Negatives (TN): 3\n",
      "False Negatives (FN): 10\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_test = df3['text']\n",
    "y_test = df3['inappropriate']\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and precision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix elements\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {precision}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f168dee-3afb-4599-9d56-a4d0fb150e9f",
   "metadata": {},
   "source": [
    "# BERT Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac164a61-fd54-43ed-b907-de3f6bb7d618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Detect the available device (CUDA or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ec91786-74f1-4aa9-85da-af0bd6f61c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6111111111111112, 'precision': 1.0, 'recall': 0.6111111111111112, 'tp': 11, 'fp': 0, 'tn': 0, 'fn': 7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess and tokenize data\n",
    "encodings = tokenizer(df1['text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Convert labels to numpy array for evaluation\n",
    "labels = df1['inappropriate'].values\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, encodings, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='binary')\n",
    "    recall = recall_score(labels, predictions, average='binary')\n",
    "    \n",
    "    # Calculate TP, FP, TN, FN using confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"tn\": tn,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "\n",
    "# Evaluate the model and print metrics\n",
    "metrics = evaluate_model(model, encodings, labels)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e899c1c-e034-4751-b332-3535b0633f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.47058823529411764, 'precision': 0.5, 'recall': 0.5555555555555556, 'tp': 5, 'fp': 5, 'tn': 3, 'fn': 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess and tokenize data\n",
    "encodings = tokenizer(df2['text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Convert labels to numpy array for evaluation\n",
    "labels = df2['inappropriate'].values\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, encodings, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='binary')\n",
    "    recall = recall_score(labels, predictions, average='binary')\n",
    "    \n",
    "    # Calculate TP, FP, TN, FN using confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"tn\": tn,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "\n",
    "# Evaluate the model and print metrics\n",
    "metrics = evaluate_model(model, encodings, labels)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73c3596-9e69-4fb7-99db-23e5b30b1411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.35294117647058826, 'precision': 1.0, 'recall': 0.15384615384615385, 'tp': 2, 'fp': 0, 'tn': 4, 'fn': 11}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess and tokenize data\n",
    "encodings = tokenizer(df3['text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Convert labels to numpy array for evaluation\n",
    "labels = df3['inappropriate'].values\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, encodings, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='binary')\n",
    "    recall = recall_score(labels, predictions, average='binary')\n",
    "    \n",
    "    # Calculate TP, FP, TN, FN using confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"tn\": tn,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "\n",
    "# Evaluate the model and print metrics\n",
    "metrics = evaluate_model(model, encodings, labels)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca03698-3e85-45ca-afdb-73b71f80e0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
